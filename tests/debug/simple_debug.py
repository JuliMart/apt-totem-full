#!/usr/bin/env python3
"""
Debugger simple para ver el anÃ¡lisis en tiempo real
"""
import sys
import os
import cv2
import numpy as np
from datetime import datetime
import json

# Agregar el path del backend
sys.path.append('/Users/julimart/Desktop/apt-totem/apt-totem-backend')

def debug_webcam_analysis():
    """Debuggear el anÃ¡lisis de la cÃ¡mara web"""
    print("ğŸ› DEBUGGER DE ANÃLISIS EN TIEMPO REAL")
    print("=" * 50)
    print("ğŸ“¹ Iniciando captura de cÃ¡mara...")
    
    # Inicializar cÃ¡mara
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("âŒ Error: No se pudo abrir la cÃ¡mara")
        return
    
    print("âœ… CÃ¡mara iniciada correctamente")
    print("ğŸ“‹ Presiona 'q' para salir, 's' para analizar frame actual")
    
    frame_count = 0
    analysis_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ Error: No se pudo leer el frame")
                break
            
            frame_count += 1
            
            # Mostrar frame
            cv2.imshow('Debug Analysis', frame)
            
            # Analizar cada 30 frames (aproximadamente cada segundo)
            if frame_count % 30 == 0:
                analysis_count += 1
                print(f"\nğŸ” === ANÃLISIS #{analysis_count} - {datetime.now().strftime('%H:%M:%S')} ===")
                
                # InformaciÃ³n bÃ¡sica del frame
                height, width, channels = frame.shape
                print(f"ğŸ“ Dimensiones: {width}x{height}x{channels}")
                
                # AnÃ¡lisis de colores bÃ¡sico
                try:
                    # Convertir a RGB
                    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    
                    # Obtener colores dominantes usando K-means
                    from sklearn.cluster import KMeans
                    
                    # Redimensionar para anÃ¡lisis mÃ¡s rÃ¡pido
                    small_frame = cv2.resize(rgb_frame, (100, 100))
                    pixels = small_frame.reshape(-1, 3)
                    
                    # K-means para 3 colores dominantes
                    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
                    kmeans.fit(pixels)
                    
                    colors = kmeans.cluster_centers_.astype(int)
                    labels = kmeans.labels_
                    
                    print(f"ğŸ¨ Colores dominantes detectados:")
                    for i, color in enumerate(colors):
                        count = np.sum(labels == i)
                        percentage = (count / len(labels)) * 100
                        print(f"  {i+1}. RGB({color[0]}, {color[1]}, {color[2]}) - {percentage:.1f}%")
                        
                        # Clasificar color bÃ¡sico
                        r, g, b = color
                        if r > g and r > b:
                            color_name = "Rojo"
                        elif g > r and g > b:
                            color_name = "Verde"
                        elif b > r and b > g:
                            color_name = "Azul"
                        elif r > 200 and g > 200 and b > 200:
                            color_name = "Blanco"
                        elif r < 50 and g < 50 and b < 50:
                            color_name = "Negro"
                        else:
                            color_name = "Mixto"
                        
                        print(f"     ClasificaciÃ³n: {color_name}")
                    
                except Exception as e:
                    print(f"âŒ Error en anÃ¡lisis de colores: {e}")
                
                # AnÃ¡lisis de brillo
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                brightness = np.mean(gray)
                print(f"ğŸ’¡ Brillo promedio: {brightness:.1f}/255")
                
                if brightness > 200:
                    print("   ğŸŒ Imagen muy brillante")
                elif brightness < 50:
                    print("   ğŸŒ™ Imagen muy oscura")
                else:
                    print("   â˜€ï¸ Brillo normal")
                
                # AnÃ¡lisis de contraste
                contrast = np.std(gray)
                print(f"ğŸ­ Contraste: {contrast:.1f}")
                
                if contrast > 50:
                    print("   ğŸ“ˆ Alto contraste")
                elif contrast < 20:
                    print("   ğŸ“‰ Bajo contraste")
                else:
                    print("   ğŸ“Š Contraste normal")
                
                print(f"âœ… AnÃ¡lisis completado")
            
            # Control de teclado
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nğŸ‘‹ Saliendo del debugger...")
                break
            elif key == ord('s'):
                # AnÃ¡lisis manual del frame actual
                analysis_count += 1
                print(f"\nğŸ” === ANÃLISIS MANUAL #{analysis_count} - {datetime.now().strftime('%H:%M:%S')} ===")
                
                # Guardar frame para anÃ¡lisis
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                frame_path = f"/Users/julimart/Desktop/apt-totem/debug_frame_{timestamp}.jpg"
                cv2.imwrite(frame_path, frame)
                print(f"ğŸ’¾ Frame guardado: {frame_path}")
                
                # AnÃ¡lisis detallado
                height, width, channels = frame.shape
                print(f"ğŸ“ Frame: {width}x{height}x{channels}")
                
                # AnÃ¡lisis de colores RGB
                b, g, r = cv2.split(frame)
                print(f"ğŸ”´ Canal Rojo - Min: {r.min()}, Max: {r.max()}, Promedio: {r.mean():.1f}")
                print(f"ğŸŸ¢ Canal Verde - Min: {g.min()}, Max: {g.max()}, Promedio: {g.mean():.1f}")
                print(f"ğŸ”µ Canal Azul - Min: {b.min()}, Max: {b.max()}, Promedio: {b.mean():.1f}")
                
                # Detectar bordes
                edges = cv2.Canny(gray, 50, 150)
                edge_pixels = np.sum(edges > 0)
                total_pixels = edges.shape[0] * edges.shape[1]
                edge_percentage = (edge_pixels / total_pixels) * 100
                print(f"ğŸ“ Bordes detectados: {edge_pixels} pÃ­xeles ({edge_percentage:.1f}%)")
                
                if edge_percentage > 10:
                    print("   ğŸ“ˆ Muchos bordes - posible textura compleja")
                elif edge_percentage < 2:
                    print("   ğŸ“‰ Pocos bordes - superficie lisa")
                else:
                    print("   ğŸ“Š Bordes normales")
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Interrumpido por usuario")
    
    finally:
        cap.release()
        cv2.destroyAllWindows()
        print("âœ… CÃ¡mara liberada")

def debug_static_image(image_path):
    """Debuggear una imagen estÃ¡tica"""
    print(f"ğŸ› DEBUGGING IMAGEN: {image_path}")
    print("=" * 50)
    
    if not os.path.exists(image_path):
        print(f"âŒ Error: Imagen no encontrada: {image_path}")
        return
    
    # Cargar imagen
    image = cv2.imread(image_path)
    if image is None:
        print("âŒ Error: No se pudo cargar la imagen")
        return
    
    print(f"âœ… Imagen cargada correctamente")
    
    # InformaciÃ³n bÃ¡sica
    height, width, channels = image.shape
    print(f"ğŸ“ Dimensiones: {width}x{height}x{channels}")
    print(f"ğŸ’¾ TamaÃ±o en memoria: {image.nbytes} bytes")
    
    # AnÃ¡lisis de colores
    print(f"\nğŸ¨ === ANÃLISIS DE COLORES ===")
    
    # Convertir a RGB
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    
    # AnÃ¡lisis por canales
    r, g, b = cv2.split(rgb_image)
    print(f"ğŸ”´ Canal Rojo - Min: {r.min()}, Max: {r.max()}, Promedio: {r.mean():.1f}")
    print(f"ğŸŸ¢ Canal Verde - Min: {g.min()}, Max: {g.max()}, Promedio: {g.mean():.1f}")
    print(f"ğŸ”µ Canal Azul - Min: {b.min()}, Max: {b.max()}, Promedio: {b.mean():.1f}")
    
    # Colores dominantes
    try:
        from sklearn.cluster import KMeans
        
        # Redimensionar para anÃ¡lisis
        small_image = cv2.resize(rgb_image, (100, 100))
        pixels = small_image.reshape(-1, 3)
        
        # K-means
        kmeans = KMeans(n_clusters=5, random_state=42, n_init=10)
        kmeans.fit(pixels)
        
        colors = kmeans.cluster_centers_.astype(int)
        labels = kmeans.labels_
        
        print(f"\nğŸŒˆ Colores dominantes:")
        for i, color in enumerate(colors):
            count = np.sum(labels == i)
            percentage = (count / len(labels)) * 100
            print(f"  {i+1}. RGB({color[0]}, {color[1]}, {color[2]}) - {percentage:.1f}%")
    
    except Exception as e:
        print(f"âŒ Error en anÃ¡lisis de colores: {e}")
    
    # AnÃ¡lisis de brillo y contraste
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    brightness = np.mean(gray)
    contrast = np.std(gray)
    
    print(f"\nğŸ’¡ === PROPIEDADES DE LA IMAGEN ===")
    print(f"ğŸ’¡ Brillo: {brightness:.1f}/255")
    print(f"ğŸ­ Contraste: {contrast:.1f}")
    
    # Detectar bordes
    edges = cv2.Canny(gray, 50, 150)
    edge_pixels = np.sum(edges > 0)
    total_pixels = edges.shape[0] * edges.shape[1]
    edge_percentage = (edge_pixels / total_pixels) * 100
    print(f"ğŸ“ Bordes: {edge_pixels} pÃ­xeles ({edge_percentage:.1f}%)")
    
    print(f"\nâœ… AnÃ¡lisis completado")

def main():
    print("ğŸ› DEBUGGER DE ANÃLISIS DE IMÃGENES")
    print("=" * 50)
    print("Opciones:")
    print("1. python3 simple_debug.py webcam    - AnÃ¡lisis en tiempo real")
    print("2. python3 simple_debug.py <imagen>  - AnÃ¡lisis de imagen estÃ¡tica")
    
    if len(sys.argv) < 2:
        print("\nâŒ Uso: python3 simple_debug.py [webcam|<ruta_imagen>]")
        return
    
    if sys.argv[1] == "webcam":
        debug_webcam_analysis()
    else:
        debug_static_image(sys.argv[1])

if __name__ == "__main__":
    main()
